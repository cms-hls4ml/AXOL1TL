#ifndef NNET_INSTR_GEN_H_
#define NNET_INSTR_GEN_H_

#include "nnet_conv1d_latency.h"
#include "nnet_helpers.h"

#include "hls_stream.h"
#include "nnet_common.h"
#include "nnet_function_stubs.h"
#include "nnet_mult.h"

namespace GTADModel_v6 {

template <class data_T, class res_T, typename CONFIG_T> class PointwiseConv1D {
  public:
    static void pointwise_conv(data_T data[CONFIG_T::in_width * CONFIG_T::n_chan],
                               res_T res[CONFIG_T::out_width * CONFIG_T::n_filt],
                               typename CONFIG_T::weight_t weights[CONFIG_T::n_chan * CONFIG_T::n_filt],
                               typename CONFIG_T::bias_t biases[CONFIG_T::n_filt]) {
        // To be implemented in subclasses
    }
};

// hls4ml insert code
template <typename inp_t, typename out_t>
void dense_da_3(inp_t inp[57], out_t out[29]) {
    #pragma HLS INLINE
    // ========================== Latency: 1 ==========================
    ap_fixed<16, 5> v183 = -bit_shift<-3>(inp[24]) - bit_shift<-3>(inp[38]);
    ap_fixed<15, 4> v81 = bit_shift<-3>(inp[20]) + bit_shift<-3>(inp[31]);
    ap_fixed<15, 5> v184 = bit_shift<-2>(inp[29]) + bit_shift<-2>(inp[39]);
    ap_fixed<15, 4> v134 = bit_shift<-3>(inp[23]) - bit_shift<-3>(inp[42]);
    ap_fixed<15, 4> v45 = bit_shift<-3>(inp[6]) - bit_shift<-3>(inp[18]);
    ap_fixed<15, 4> v57 = bit_shift<-3>(inp[17]) + bit_shift<-3>(inp[48]);
    ap_fixed<15, 4> v0 = bit_shift<-3>(inp[9]) - bit_shift<-3>(inp[12]);
    ap_fixed<15, 4> v119 = bit_shift<-3>(inp[15]) + bit_shift<-3>(inp[25]);
    ap_fixed<15, 4> v9 = bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[16]);
    ap_fixed<15, 4> v12 = bit_shift<-3>(inp[35]) + bit_shift<-3>(inp[43]);
    ap_fixed<15, 4> v15 = bit_shift<-3>(inp[33]) - bit_shift<-3>(inp[49]);
    ap_fixed<15, 4> v24 = bit_shift<-3>(inp[21]) - bit_shift<-3>(inp[41]);
    ap_fixed<15, 4> v27 = bit_shift<-3>(inp[19]) + bit_shift<-3>(inp[52]);
    ap_fixed<15, 4> v123 = bit_shift<-3>(inp[0]) + bit_shift<-3>(inp[46]);
    ap_fixed<15, 4> v141 = bit_shift<-3>(inp[33]) + bit_shift<-3>(inp[36]);
    ap_fixed<15, 4> v29 = bit_shift<-3>(inp[27]) + bit_shift<-3>(inp[30]);
    ap_fixed<15, 4> v13 = bit_shift<-3>(inp[8]) + bit_shift<-3>(inp[32]);
    ap_fixed<16, 5> v73 = bit_shift<-3>(inp[14]) - bit_shift<-2>(inp[10]);
    ap_fixed<15, 4> v199 = bit_shift<-3>(inp[10]) - bit_shift<-3>(inp[54]);
    ap_fixed<15, 4> v18 = bit_shift<-3>(inp[3]) + bit_shift<-3>(inp[15]);
    ap_fixed<15, 4> v20 = bit_shift<-3>(inp[4]) - bit_shift<-3>(inp[7]);
    ap_fixed<15, 5> v200 = bit_shift<-2>(inp[28]) + bit_shift<-2>(inp[34]);
    ap_fixed<15, 4> v49 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[29]);
    ap_fixed<16, 5> v198 = -bit_shift<-3>(inp[18]) - bit_shift<-3>(inp[52]);
    ap_fixed<15, 4> v5 = bit_shift<-3>(inp[47]) + bit_shift<-3>(inp[48]);
    ap_fixed<17, 6> v172 = bit_shift<-3>(inp[36]) - bit_shift<-1>(inp[36]);
    ap_fixed<15, 4> v71 = bit_shift<-3>(inp[26]) - bit_shift<-3>(inp[35]);
    ap_fixed<15, 4> v77 = bit_shift<-3>(inp[16]) - bit_shift<-3>(inp[43]);
    ap_fixed<16, 5> v16 = bit_shift<-3>(inp[37]) - bit_shift<-2>(inp[30]);
    ap_fixed<15, 4> v6 = bit_shift<-3>(inp[5]) - bit_shift<-3>(inp[11]);
    ap_fixed<15, 4> v1 = bit_shift<-3>(inp[25]) - bit_shift<-3>(inp[39]);
    ap_fixed<15, 4> v60 = bit_shift<-3>(inp[31]) + bit_shift<-3>(inp[42]);
    ap_fixed<15, 4> v8 = bit_shift<-3>(inp[0]) + bit_shift<-3>(inp[17]);
    ap_fixed<15, 4> v39 = bit_shift<-3>(inp[40]) - bit_shift<-3>(inp[51]);
    ap_fixed<15, 4> v218 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[11]);
    ap_fixed<15, 4> v219 = bit_shift<-3>(inp[28]) + bit_shift<-3>(inp[29]);
    ap_fixed<16, 6> v217 = -bit_shift<-2>(inp[9]) - bit_shift<-2>(inp[34]);
    ap_fixed<16, 5> v220 = bit_shift<-2>(inp[46]) - bit_shift<-3>(inp[49]);
    ap_fixed<16, 5> v153 = bit_shift<-3>(inp[41]) + bit_shift<-2>(inp[27]);
    ap_fixed<15, 4> v10 = bit_shift<-3>(inp[2]) - bit_shift<-3>(inp[56]);
    ap_fixed<15, 4> v2 = bit_shift<-3>(inp[13]) - bit_shift<-3>(inp[14]);
    ap_fixed<15, 4> v7 = bit_shift<-3>(inp[18]) + bit_shift<-3>(inp[44]);
    ap_fixed<15, 4> v50 = bit_shift<-3>(inp[23]) + bit_shift<-3>(inp[54]);
    ap_fixed<15, 4> v58 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[3]);
    ap_fixed<15, 4> v4 = bit_shift<-3>(inp[31]) - bit_shift<-3>(inp[36]);
    ap_fixed<15, 4> v68 = bit_shift<-3>(inp[7]) - bit_shift<-3>(inp[25]);
    ap_fixed<15, 4> v125 = bit_shift<-3>(inp[5]) + bit_shift<-3>(inp[24]);
    ap_fixed<15, 4> v37 = bit_shift<-3>(inp[30]) - bit_shift<-3>(inp[55]);
    ap_fixed<15, 4> v235 = bit_shift<-3>(inp[5]) - bit_shift<-3>(inp[32]);
    ap_fixed<15, 4> v138 = bit_shift<-3>(inp[1]) - bit_shift<-3>(inp[16]);
    ap_fixed<15, 4> v31 = bit_shift<-3>(inp[34]) + bit_shift<-3>(inp[46]);
    ap_fixed<15, 4> v88 = bit_shift<-3>(inp[19]) - bit_shift<-3>(inp[51]);
    ap_fixed<15, 5> v236 = -bit_shift<-2>(inp[20]) + bit_shift<-2>(inp[48]);
    ap_fixed<15, 4> v11 = bit_shift<-3>(inp[29]) - bit_shift<-3>(inp[50]);
    ap_fixed<15, 4> v42 = bit_shift<-3>(inp[21]) + bit_shift<-3>(inp[41]);
    ap_fixed<15, 4> v129 = bit_shift<-3>(inp[2]) - bit_shift<-3>(inp[22]);
    ap_fixed<15, 4> v3 = bit_shift<-3>(inp[26]) - bit_shift<-3>(inp[27]);
    ap_fixed<15, 4> v25 = bit_shift<-3>(inp[24]) - bit_shift<-3>(inp[39]);
    ap_fixed<16, 5> v251 = -bit_shift<-3>(inp[10]) - bit_shift<-3>(inp[19]);
    ap_fixed<15, 4> v17 = bit_shift<-3>(inp[1]) - bit_shift<-3>(inp[33]);
    ap_fixed<15, 4> v110 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[35]);
    ap_fixed<15, 4> v131 = bit_shift<-3>(inp[44]) + bit_shift<-3>(inp[45]);
    ap_fixed<16, 5> v28 = bit_shift<-3>(inp[36]) + bit_shift<-2>(inp[27]);
    ap_fixed<17, 6> v175 = bit_shift<-3>(inp[17]) - bit_shift<-1>(inp[32]);
    ap_fixed<15, 4> v30 = bit_shift<-3>(inp[31]) - bit_shift<-3>(inp[53]);
    ap_fixed<15, 4> v32 = bit_shift<-3>(inp[2]) - bit_shift<-3>(inp[8]);
    ap_fixed<15, 4> v46 = bit_shift<-3>(inp[6]) + bit_shift<-3>(inp[22]);
    ap_fixed<16, 5> v51 = bit_shift<-3>(inp[15]) - bit_shift<-2>(inp[16]);
    ap_fixed<15, 4> v22 = bit_shift<-3>(inp[20]) + bit_shift<-3>(inp[28]);
    ap_fixed<15, 5> v266 = -bit_shift<-2>(inp[11]) + bit_shift<-2>(inp[16]);
    ap_fixed<17, 6> v268 = -bit_shift<-3>(inp[33]) - bit_shift<-1>(inp[35]);
    ap_fixed<15, 4> v21 = bit_shift<-3>(inp[42]) + bit_shift<-3>(inp[45]);
    ap_fixed<15, 4> v126 = bit_shift<-3>(inp[3]) + bit_shift<-3>(inp[32]);
    ap_fixed<15, 4> v267 = bit_shift<-3>(inp[20]) + bit_shift<-3>(inp[27]);
    ap_fixed<15, 4> v109 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[21]);
    ap_fixed<15, 4> v35 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[40]);
    ap_fixed<16, 5> v282 = -bit_shift<-3>(inp[5]) - bit_shift<-2>(inp[27]);
    ap_fixed<15, 4> v283 = bit_shift<-3>(inp[43]) + bit_shift<-3>(inp[50]);
    ap_fixed<15, 4> v76 = bit_shift<-3>(inp[40]) + bit_shift<-3>(inp[54]);
    ap_fixed<15, 4> v115 = bit_shift<-3>(inp[12]) - bit_shift<-3>(inp[39]);
    ap_fixed<15, 4> v124 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[47]);
    ap_fixed<15, 4> v33 = bit_shift<-3>(inp[37]) - bit_shift<-3>(inp[38]);
    ap_fixed<15, 5> v294 = bit_shift<-2>(inp[11]) - bit_shift<-2>(inp[21]);
    ap_fixed<15, 4> v144 = bit_shift<-3>(inp[29]) - bit_shift<-3>(inp[48]);
    ap_fixed<15, 4> v127 = bit_shift<-3>(inp[19]) + bit_shift<-3>(inp[24]);
    ap_fixed<16, 5> v295 = bit_shift<-2>(inp[37]) - bit_shift<-3>(inp[47]);
    ap_fixed<15, 4> v99 = bit_shift<-3>(inp[35]) - bit_shift<-3>(inp[56]);
    ap_fixed<15, 4> v133 = bit_shift<-3>(inp[9]) - bit_shift<-3>(inp[45]);
    ap_fixed<16, 5> v312 = bit_shift<-2>(inp[0]) + bit_shift<-3>(inp[14]);
    ap_fixed<15, 4> v26 = bit_shift<-3>(inp[34]) + bit_shift<-3>(inp[52]);
    ap_fixed<16, 5> v162 = bit_shift<-3>(inp[40]) + bit_shift<-2>(inp[28]);
    ap_fixed<16, 6> v311 = -bit_shift<-2>(inp[25]) - bit_shift<-2>(inp[49]);
    ap_fixed<15, 4> v107 = bit_shift<-3>(inp[10]) + bit_shift<-3>(inp[30]);
    ap_fixed<15, 4> v161 = bit_shift<-3>(inp[42]) + bit_shift<-3>(inp[50]);
    ap_fixed<15, 5> v329 = bit_shift<-2>(inp[3]) - bit_shift<-2>(inp[38]);
    ap_fixed<15, 4> v330 = bit_shift<-3>(inp[7]) + bit_shift<-3>(inp[44]);
    ap_fixed<15, 4> v48 = bit_shift<-3>(inp[9]) - bit_shift<-3>(inp[52]);
    ap_fixed<15, 4> v96 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[14]);
    ap_fixed<16, 5> v346 = -bit_shift<-2>(inp[13]) - bit_shift<-3>(inp[45]);
    ap_fixed<16, 5> v170 = bit_shift<-3>(inp[6]) + bit_shift<-2>(inp[33]);
    ap_fixed<15, 4> v155 = bit_shift<-3>(inp[24]) - bit_shift<-3>(inp[26]);
    ap_fixed<15, 4> v121 = bit_shift<-3>(inp[11]) + bit_shift<-3>(inp[27]);
    ap_fixed<16, 7> v345 = -bit_shift<-1>(inp[32]) - bit_shift<-1>(inp[38]);
    ap_fixed<15, 4> v112 = bit_shift<-3>(inp[5]) - bit_shift<-3>(inp[34]);
    ap_fixed<15, 4> v14 = bit_shift<-3>(inp[10]) + bit_shift<-3>(inp[22]);
    ap_fixed<15, 4> v19 = bit_shift<-3>(inp[7]) - bit_shift<-3>(inp[23]);
    ap_fixed<17, 6> v360 = bit_shift<-1>(inp[33]) - bit_shift<-3>(inp[55]);
    ap_fixed<16, 5> v156 = bit_shift<-3>(inp[33]) - bit_shift<-2>(inp[7]);
    ap_fixed<15, 4> v69 = bit_shift<-3>(inp[18]) - bit_shift<-3>(inp[34]);
    ap_fixed<15, 4> v80 = bit_shift<-3>(inp[9]) - bit_shift<-3>(inp[20]);
    ap_fixed<15, 4> v140 = bit_shift<-3>(inp[14]) - bit_shift<-3>(inp[32]);
    ap_fixed<15, 4> v146 = bit_shift<-3>(inp[44]) - bit_shift<-3>(inp[46]);
    ap_fixed<16, 5> v53 = bit_shift<-3>(inp[23]) - bit_shift<-2>(inp[6]);
    ap_fixed<15, 4> v23 = bit_shift<-3>(inp[53]) + bit_shift<-3>(inp[54]);
    ap_fixed<15, 4> v59 = bit_shift<-3>(inp[49]) + bit_shift<-3>(inp[50]);
    ap_fixed<16, 6> v373 = -bit_shift<-2>(inp[6]) - bit_shift<-2>(inp[32]);
    ap_fixed<17, 6> v375 = -bit_shift<-1>(inp[36]) - bit_shift<-3>(inp[53]);
    ap_fixed<15, 4> v130 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[22]);
    ap_fixed<15, 4> v374 = bit_shift<-3>(inp[15]) + bit_shift<-3>(inp[18]);
    ap_fixed<15, 4> v56 = bit_shift<-3>(inp[17]) - bit_shift<-3>(inp[51]);
    ap_fixed<17, 6> v388 = -bit_shift<-1>(inp[38]) - bit_shift<-3>(inp[49]);
    ap_fixed<15, 4> v148 = bit_shift<-3>(inp[30]) - bit_shift<-3>(inp[37]);
    ap_fixed<15, 4> v150 = bit_shift<-3>(inp[32]) - bit_shift<-3>(inp[53]);
    ap_fixed<15, 4> v402 = bit_shift<-3>(inp[9]) + bit_shift<-3>(inp[13]);
    ap_fixed<15, 4> v404 = bit_shift<-3>(inp[39]) - bit_shift<-3>(inp[51]);
    ap_fixed<15, 4> v145 = bit_shift<-3>(inp[38]) + bit_shift<-3>(inp[49]);
    ap_fixed<15, 5> v403 = bit_shift<-2>(inp[12]) - bit_shift<-2>(inp[40]);
    ap_fixed<16, 5> v79 = bit_shift<-3>(inp[37]) + bit_shift<-2>(inp[36]);
    ap_fixed<16, 6> v419 = -bit_shift<-2>(inp[3]) - bit_shift<-2>(inp[36]);
    ap_fixed<16, 5> v421 = bit_shift<-2>(inp[34]) + bit_shift<-3>(inp[50]);
    ap_fixed<15, 4> v420 = bit_shift<-3>(inp[22]) + bit_shift<-3>(inp[32]);
    ap_fixed<15, 4> v65 = bit_shift<-3>(inp[47]) - bit_shift<-3>(inp[56]);
    ap_fixed<16, 5> v41 = bit_shift<-3>(inp[15]) + bit_shift<-2>(inp[33]);
    ap_fixed<16, 6> v435 = bit_shift<-1>(inp[0]) - bit_shift<-2>(inp[35]);
    ap_fixed<15, 4> v147 = bit_shift<-3>(inp[37]) + bit_shift<-3>(inp[46]);
    ap_fixed<15, 4> v40 = bit_shift<-3>(inp[12]) - bit_shift<-3>(inp[44]);
    ap_fixed<15, 4> v104 = bit_shift<-3>(inp[13]) + bit_shift<-3>(inp[55]);
    ap_fixed<15, 6> v454 = bit_shift<-1>(inp[0]) - bit_shift<-1>(inp[31]);
    ap_fixed<15, 4> v455 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[33]);
    ap_fixed<15, 4> v137 = bit_shift<-3>(inp[16]) - bit_shift<-3>(inp[50]);
    ap_fixed<16, 6> v471 = bit_shift<-2>(inp[30]) + bit_shift<-1>(inp[42]);
    ap_fixed<15, 4> v470 = bit_shift<-3>(inp[47]) + bit_shift<-3>(inp[55]);
    ap_fixed<15, 4> v135 = bit_shift<-3>(inp[13]) + bit_shift<-3>(inp[42]);
    ap_fixed<16, 5> v483 = -bit_shift<-3>(inp[17]) - bit_shift<-3>(inp[26]);
    ap_fixed<16, 5> v484 = -bit_shift<-3>(inp[36]) - bit_shift<-3>(inp[56]);
    ap_fixed<15, 6> v498 = -bit_shift<-1>(inp[30]) + bit_shift<-1>(inp[36]);
    ap_fixed<16, 5> v499 = bit_shift<-3>(inp[39]) - bit_shift<-2>(inp[42]);
    ap_fixed<16, 6> v522 = -bit_shift<-2>(inp[2]) - bit_shift<-2>(inp[41]);
    ap_fixed<15, 4> v523 = bit_shift<-3>(inp[21]) - bit_shift<-3>(inp[54]);
    ap_fixed<15, 4> v139 = bit_shift<-3>(inp[28]) - bit_shift<-3>(inp[36]);
    ap_fixed<15, 4> v542 = bit_shift<-3>(inp[12]) + bit_shift<-3>(inp[38]);
    ap_fixed<15, 4> v556 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[25]);
    ap_fixed<16, 5> v571 = -bit_shift<-2>(inp[12]) + bit_shift<-3>(inp[40]);
    ap_fixed<16, 5> v569 = -bit_shift<-3>(inp[26]) - bit_shift<-3>(inp[29]);
    ap_fixed<16, 5> v570 = -bit_shift<-3>(inp[46]) - bit_shift<-3>(inp[53]);
    ap_fixed<16, 6> v585 = -bit_shift<-2>(inp[0]) - bit_shift<-1>(inp[35]);
    ap_fixed<16, 5> v601 = -bit_shift<-3>(inp[11]) - bit_shift<-3>(inp[45]);
    ap_fixed<15, 5> v602 = -bit_shift<-2>(inp[28]) + bit_shift<-2>(inp[35]);
    ap_fixed<15, 4> v618 = bit_shift<-3>(inp[49]) + bit_shift<-3>(inp[51]);
    // ========================== Latency: 2 ==========================
    ap_fixed<17, 6> v185 = v183 - v81;
    ap_fixed<16, 6> v186 = v184 - bit_shift<1>(v134);
    ap_fixed<16, 5> v93 = v45 - v57;
    ap_fixed<16, 5> v187 = -v0 + v119;
    ap_fixed<16, 5> v61 = bit_shift<-3>(inp[11]) - v9;
    ap_fixed<16, 5> v84 = v12 - v15;
    ap_fixed<16, 5> v85 = v24 + v27;
    ap_fixed<18, 7> v188 = v123 + bit_shift<2>(v141);
    ap_fixed<18, 7> v174 = v29 - bit_shift<2>(v29);
    ap_fixed<17, 6> v108 = v13 + v73;
    ap_fixed<16, 5> v203 = v199 - v18;
    ap_fixed<16, 5> v205 = v20 - v24;
    ap_fixed<16, 6> v204 = v200 + bit_shift<1>(v49);
    ap_fixed<17, 6> v202 = v198 - v5;
    ap_fixed<18, 7> v201 = -bit_shift<-1>(inp[27]) + v172;
    ap_fixed<17, 6> v206 = v71 - bit_shift<1>(v77);
    ap_fixed<17, 6> v103 = v0 - v16;
    ap_fixed<16, 5> v43 = bit_shift<-3>(inp[20]) + v6;
    ap_fixed<16, 5> v63 = v1 - v13;
    ap_fixed<16, 5> v92 = bit_shift<-3>(inp[53]) + v60;
    ap_fixed<16, 5> v105 = v8 - v39;
    ap_fixed<16, 5> v221 = v218 + bit_shift<-3>(inp[48]);
    ap_fixed<16, 5> v224 = v219 + v9;
    ap_fixed<17, 7> v222 = v217 + bit_shift<1>(v16);
    ap_fixed<17, 6> v223 = v220 + v153;
    ap_fixed<16, 5> v36 = v2 + v7;
    ap_fixed<16, 5> v225 = v50 + v58;
    ap_fixed<16, 5> v54 = v4 + v12;
    ap_fixed<16, 5> v226 = v68 + v125;
    ap_fixed<16, 5> v171 = bit_shift<-3>(inp[19]) - v37;
    ap_fixed<16, 5> v237 = v235 + bit_shift<-3>(inp[44]);
    ap_fixed<16, 5> v240 = v8 + v31;
    ap_fixed<16, 5> v169 = v88 + bit_shift<-2>(inp[15]);
    ap_fixed<16, 6> v239 = v236 + bit_shift<1>(v11);
    ap_fixed<17, 6> v238 = -v42 - v60;
    ap_fixed<17, 6> v241 = v73 + v129;
    ap_fixed<17, 6> v70 = v15 - bit_shift<-1>(inp[32]);
    ap_fixed<16, 5> v78 = v3 + v50;
    ap_fixed<16, 5> v47 = bit_shift<-3>(inp[25]) - v25;
    ap_fixed<16, 5> v252 = v251 + bit_shift<-3>(inp[47]);
    ap_fixed<16, 5> v254 = -v17 + v20;
    ap_fixed<16, 6> v256 = -bit_shift<1>(v37) - bit_shift<1>(v110);
    ap_fixed<18, 7> v257 = bit_shift<2>(v17) - v131;
    ap_fixed<18, 7> v253 = -bit_shift<1>(v28) + v175;
    ap_fixed<16, 5> v255 = v30 - v32;
    ap_fixed<16, 5> v75 = v1 + v46;
    ap_fixed<16, 5> v67 = v22 + v31;
    ap_fixed<16, 5> v38 = bit_shift<-3>(inp[5]) + v0;
    ap_fixed<16, 6> v270 = v266 + bit_shift<1>(v0);
    ap_fixed<16, 5> v83 = bit_shift<-3>(inp[43]) + v16;
    ap_fixed<17, 6> v269 = v268 - v21;
    ap_fixed<18, 7> v272 = -bit_shift<1>(v28) - v126;
    ap_fixed<16, 5> v271 = v267 + v109;
    ap_fixed<16, 5> v166 = bit_shift<-3>(inp[5]) + v35;
    ap_fixed<16, 5> v168 = bit_shift<-3>(inp[23]) - v5;
    ap_fixed<16, 5> v72 = bit_shift<-3>(inp[38]) + v11;
    ap_fixed<16, 5> v142 = bit_shift<-3>(inp[56]) + v30;
    ap_fixed<17, 6> v284 = v282 - v27;
    ap_fixed<16, 5> v285 = v283 - v15;
    ap_fixed<16, 5> v286 = v18 + v76;
    ap_fixed<16, 5> v287 = v115 + v124;
    ap_fixed<16, 5> v118 = v33 - v42;
    ap_fixed<16, 6> v297 = v294 + bit_shift<1>(v4);
    ap_fixed<16, 6> v299 = bit_shift<1>(v22) + bit_shift<1>(v32);
    ap_fixed<16, 6> v300 = bit_shift<1>(v39) - bit_shift<1>(v127);
    ap_fixed<16, 5> v296 = v295 + bit_shift<-3>(inp[50]);
    ap_fixed<16, 5> v298 = v9 - v18;
    ap_fixed<16, 5> v301 = v99 - v133;
    ap_fixed<17, 6> v314 = v312 - v26;
    ap_fixed<16, 5> v317 = -v17 - v25;
    ap_fixed<17, 7> v313 = v311 - bit_shift<-1>(inp[27]);
    ap_fixed<17, 6> v315 = -v42 - v49;
    ap_fixed<17, 6> v316 = -v107 - v161;
    ap_fixed<16, 5> v62 = bit_shift<-3>(inp[3]) + v0;
    ap_fixed<16, 5> v158 = bit_shift<-3>(inp[35]) + v51;
    ap_fixed<16, 6> v332 = v329 + bit_shift<1>(v4);
    ap_fixed<16, 5> v333 = v330 - v48;
    ap_fixed<17, 7> v331 = -bit_shift<-1>(inp[29]) - bit_shift<1>(v8);
    ap_fixed<18, 7> v182 = bit_shift<-3>(inp[37]) - bit_shift<2>(v29);
    ap_fixed<16, 5> v34 = v3 - v5;
    ap_fixed<16, 5> v334 = v96 + v134;
    ap_fixed<16, 5> v97 = v6 + v17;
    ap_fixed<17, 6> v347 = v346 - v170;
    ap_fixed<16, 5> v44 = bit_shift<-3>(inp[41]) - v1;
    ap_fixed<16, 5> v350 = v48 + v121;
    ap_fixed<17, 7> v348 = v345 - bit_shift<1>(v28);
    ap_fixed<16, 6> v349 = bit_shift<1>(v32) - bit_shift<1>(v112);
    ap_fixed<16, 5> v66 = v7 + v22;
    ap_fixed<16, 5> v116 = v9 - v11;
    ap_fixed<16, 5> v52 = v5 - v14;
    ap_fixed<16, 5> v64 = v19 - bit_shift<-2>(inp[4]);
    ap_fixed<18, 7> v361 = v360 - bit_shift<1>(v16);
    ap_fixed<16, 5> v165 = bit_shift<-3>(inp[47]) + v12;
    ap_fixed<16, 5> v362 = v69 - v80;
    ap_fixed<16, 5> v89 = v14 - v21;
    ap_fixed<16, 5> v363 = v140 - v146;
    ap_fixed<16, 5> v90 = bit_shift<-3>(inp[48]) + v10;
    ap_fixed<16, 5> v55 = bit_shift<-3>(inp[30]) - v23;
    ap_fixed<16, 5> v106 = v8 - v24;
    ap_fixed<18, 7> v376 = v373 + v375;
    ap_fixed<17, 6> v379 = -v99 - bit_shift<1>(v146);
    ap_fixed<17, 6> v377 = -v130 - v156;
    ap_fixed<16, 5> v378 = v374 + v49;
    ap_fixed<16, 5> v117 = v56 - v76;
    ap_fixed<16, 5> v82 = bit_shift<-3>(inp[43]) - v2;
    ap_fixed<18, 7> v389 = v388 - bit_shift<1>(v96);
    ap_fixed<16, 5> v390 = v5 + v14;
    ap_fixed<16, 5> v391 = -v24 + v27;
    ap_fixed<16, 5> v392 = -v56 + v115;
    ap_fixed<16, 5> v393 = -v148 - v150;
    ap_fixed<16, 5> v407 = v402 + v404;
    ap_fixed<16, 5> v409 = v6 + v30;
    ap_fixed<16, 5> v152 = bit_shift<-3>(inp[16]) + v7;
    ap_fixed<16, 5> v410 = v124 + v145;
    ap_fixed<17, 6> v408 = v403 - v161;
    ap_fixed<17, 6> v406 = -v14 - v109;
    ap_fixed<17, 7> v405 = -bit_shift<-1>(inp[34]) + bit_shift<1>(v79);
    ap_fixed<17, 6> v422 = v419 + v421;
    ap_fixed<16, 5> v423 = v420 + v33;
    ap_fixed<17, 7> v425 = -bit_shift<1>(v2) + bit_shift<2>(v148);
    ap_fixed<16, 5> v424 = v39 + v57;
    ap_fixed<17, 6> v102 = v30 + v41;
    ap_fixed<16, 5> v159 = bit_shift<-3>(inp[18]) + v37;
    ap_fixed<16, 5> v163 = bit_shift<-3>(inp[43]) + v20;
    ap_fixed<18, 7> v437 = v435 + v172;
    ap_fixed<17, 6> v438 = -v145 - v147;
    ap_fixed<16, 5> v120 = v35 + v40;
    ap_fixed<16, 6> v441 = -bit_shift<1>(v68) - bit_shift<1>(v69);
    ap_fixed<16, 5> v136 = bit_shift<-3>(inp[28]) - v3;
    ap_fixed<16, 5> v436 = -bit_shift<-3>(inp[8]) + v21;
    ap_fixed<16, 5> v439 = v25 + v46;
    ap_fixed<16, 5> v440 = v65 - v77;
    ap_fixed<16, 5> v442 = v104 + v144;
    ap_fixed<17, 7> v460 = v454 - bit_shift<1>(v45);
    ap_fixed<17, 7> v457 = -bit_shift<1>(v21) - bit_shift<1>(v31);
    ap_fixed<16, 5> v456 = v455 + bit_shift<-2>(inp[7]);
    ap_fixed<16, 5> v458 = v13 - v22;
    ap_fixed<16, 5> v459 = v129 - v137;
    ap_fixed<17, 7> v472 = v471 + bit_shift<1>(v131);
    ap_fixed<16, 5> v473 = v470 - v19;
    ap_fixed<16, 5> v474 = -v58 - v137;
    ap_fixed<16, 5> v87 = v23 + v48;
    ap_fixed<16, 5> v178 = bit_shift<-3>(inp[27]) + v135;
    ap_fixed<17, 6> v485 = v483 - bit_shift<-2>(inp[23]);
    ap_fixed<17, 6> v486 = v484 - v81;
    ap_fixed<16, 5> v488 = -v15 - v32;
    ap_fixed<17, 6> v489 = v77 + bit_shift<1>(v150);
    ap_fixed<17, 6> v487 = -v121 - v130;
    ap_fixed<17, 6> v500 = v499 + v2;
    ap_fixed<16, 5> v501 = v33 - v68;
    ap_fixed<16, 5> v94 = bit_shift<-3>(inp[8]) - v26;
    ap_fixed<16, 5> v502 = v127 + v133;
    ap_fixed<17, 6> v511 = bit_shift<-2>(inp[19]) + v41;
    ap_fixed<16, 5> v74 = v20 - v26;
    ap_fixed<17, 6> v512 = -v81 - bit_shift<1>(v123);
    ap_fixed<17, 6> v160 = v79 + bit_shift<-2>(inp[39]);
    ap_fixed<16, 6> v524 = v522 + bit_shift<-2>(inp[52]);
    ap_fixed<16, 5> v529 = -v110 - v112;
    ap_fixed<16, 5> v526 = v523 + v0;
    ap_fixed<16, 5> v527 = v7 + v9;
    ap_fixed<17, 6> v525 = -v13 + v16;
    ap_fixed<16, 6> v528 = -bit_shift<1>(v15) + bit_shift<1>(v139);
    ap_fixed<16, 5> v545 = v542 + v88;
    ap_fixed<16, 5> v86 = v4 + v6;
    ap_fixed<16, 6> v543 = -bit_shift<-1>(inp[38]) + bit_shift<1>(v45);
    ap_fixed<17, 6> v544 = -v49 - v153;
    ap_fixed<16, 5> v557 = v556 - bit_shift<-3>(inp[55]);
    ap_fixed<16, 5> v559 = -v11 - v139;
    ap_fixed<16, 7> v560 = bit_shift<2>(v35) + bit_shift<2>(v141);
    ap_fixed<17, 6> v558 = -v107 - v147;
    ap_fixed<17, 6> v572 = v571 + v569;
    ap_fixed<17, 6> v573 = v570 - v126;
    ap_fixed<17, 7> v575 = bit_shift<1>(v33) - bit_shift<1>(v41);
    ap_fixed<16, 5> v574 = v8 + v25;
    ap_fixed<16, 5> v177 = v80 + bit_shift<-2>(inp[10]);
    ap_fixed<18, 7> v587 = v585 + v175;
    ap_fixed<17, 7> v590 = bit_shift<2>(v4) + bit_shift<1>(v17);
    ap_fixed<16, 5> v586 = bit_shift<-3>(inp[45]) + v1;
    ap_fixed<16, 5> v588 = v10 - v18;
    ap_fixed<16, 5> v589 = v59 + v104;
    ap_fixed<16, 5> v113 = v40 + bit_shift<-2>(inp[29]);
    ap_fixed<17, 6> v603 = v601 - v13;
    ap_fixed<17, 6> v607 = -bit_shift<1>(v69) - v138;
    ap_fixed<16, 6> v604 = v602 + bit_shift<1>(v58);
    ap_fixed<16, 5> v605 = -v3 + v39;
    ap_fixed<16, 5> v606 = v42 - v119;
    ap_fixed<16, 5> v620 = v618 + v19;
    ap_fixed<17, 6> v621 = bit_shift<1>(v21) - v28;
    ap_fixed<17, 7> v619 = -bit_shift<1>(v31) + bit_shift<1>(v79);
    ap_fixed<16, 5> v622 = v71 + v125;
    // ========================== Latency: 3 ==========================
    ap_fixed<18, 7> v190 = v185 + v186;
    ap_fixed<17, 6> v191 = v187 + v61;
    ap_fixed<17, 6> v192 = v84 - v85;
    ap_fixed<19, 8> v189 = v188 - v174;
    ap_fixed<17, 6> v176 = v108 - bit_shift<-2>(inp[40]);
    ap_fixed<17, 6> v209 = v203 + v205;
    ap_fixed<18, 7> v207 = v202 + v201;
    ap_fixed<18, 7> v208 = v206 - v103;
    ap_fixed<17, 6> v210 = v43 + v63;
    ap_fixed<17, 6> v211 = v92 - v105;
    ap_fixed<17, 6> v227 = v221 + v224;
    ap_fixed<18, 7> v228 = v222 + v223;
    ap_fixed<17, 6> v91 = v10 + v36;
    ap_fixed<17, 6> v229 = v225 - v54;
    ap_fixed<17, 6> v230 = v226 - v171;
    ap_fixed<17, 6> v242 = v237 + bit_shift<1>(v138);
    ap_fixed<17, 6> v245 = v240 + v169;
    ap_fixed<18, 7> v244 = v239 - v103;
    ap_fixed<18, 7> v243 = v238 + v241;
    ap_fixed<18, 7> v122 = v70 + v78;
    ap_fixed<16, 5> v167 = bit_shift<-3>(inp[55]) + v47;
    ap_fixed<17, 6> v259 = v252 + v254;
    ap_fixed<19, 8> v258 = v257 + v253;
    ap_fixed<17, 6> v260 = v255 + v75;
    ap_fixed<17, 6> v114 = v51 + v67;
    ap_fixed<17, 6> v154 = v2 + v38;
    ap_fixed<17, 7> v274 = v270 + bit_shift<1>(v83);
    ap_fixed<18, 7> v273 = v269 + v272;
    ap_fixed<17, 6> v275 = v271 - v47;
    ap_fixed<17, 6> v276 = -v166 - v168;
    ap_fixed<17, 6> v173 = v72 + bit_shift<-2>(inp[19]);
    ap_fixed<17, 6> v180 = v142 + bit_shift<-1>(inp[29]);
    ap_fixed<18, 7> v288 = v284 - bit_shift<1>(v57);
    ap_fixed<17, 6> v289 = v285 + v286;
    ap_fixed<17, 6> v290 = v287 + v118;
    ap_fixed<17, 7> v302 = v297 + bit_shift<1>(v144);
    ap_fixed<17, 7> v304 = v299 + v300;
    ap_fixed<17, 6> v305 = -v36 + v75;
    ap_fixed<17, 6> v303 = v296 + v298;
    ap_fixed<17, 6> v318 = v314 - v162;
    ap_fixed<17, 6> v321 = v317 - v43;
    ap_fixed<17, 7> v320 = v313 - bit_shift<1>(v83);
    ap_fixed<18, 7> v319 = v315 + v316;
    ap_fixed<17, 6> v322 = v62 - v78;
    ap_fixed<17, 6> v323 = v93 - v158;
    ap_fixed<17, 6> v335 = v333 + v162;
    ap_fixed<19, 8> v336 = v331 + v182;
    ap_fixed<17, 6> v337 = -v34 + v63;
    ap_fixed<17, 6> v338 = v334 + v97;
    ap_fixed<17, 6> v339 = -v158 - v171;
    ap_fixed<17, 6> v351 = v347 - v155;
    ap_fixed<17, 6> v353 = -v44 + v350;
    ap_fixed<18, 8> v352 = v348 + v349;
    ap_fixed<17, 6> v354 = v66 + v116;
    ap_fixed<17, 6> v95 = v52 - v64;
    ap_fixed<18, 7> v364 = v361 - v156;
    ap_fixed<17, 6> v365 = v47 + v362;
    ap_fixed<17, 6> v366 = v89 + v363;
    ap_fixed<17, 6> v132 = v53 - v90;
    ap_fixed<17, 6> v143 = v18 + v55;
    ap_fixed<17, 6> v111 = v28 + v106;
    ap_fixed<18, 7> v380 = v376 + v379;
    ap_fixed<18, 7> v382 = bit_shift<1>(v118) + v377;
    ap_fixed<17, 6> v381 = v378 - v117;
    ap_fixed<17, 6> v101 = v34 - v62;
    ap_fixed<17, 6> v151 = v27 - v82;
    ap_fixed<17, 6> v164 = v4 + v43;
    ap_fixed<18, 7> v394 = v389 + bit_shift<1>(v18);
    ap_fixed<17, 6> v395 = v390 + v391;
    ap_fixed<17, 6> v98 = v53 + v66;
    ap_fixed<17, 6> v396 = v54 + v392;
    ap_fixed<17, 6> v397 = v72 + v393;
    ap_fixed<17, 6> v413 = v407 + v409;
    ap_fixed<17, 6> v414 = v67 + v410;
    ap_fixed<18, 7> v411 = v408 + v406;
    ap_fixed<19, 8> v412 = v405 - v174;
    ap_fixed<18, 7> v426 = v422 + v423;
    ap_fixed<17, 6> v427 = v38 + v424;
    ap_fixed<17, 6> v428 = v44 + v61;
    ap_fixed<17, 6> v149 = v65 - v102;
    ap_fixed<17, 6> v429 = -v159 - v163;
    ap_fixed<18, 7> v443 = v437 + v438;
    ap_fixed<17, 7> v446 = v441 + bit_shift<1>(v136);
    ap_fixed<17, 6> v444 = v436 + v439;
    ap_fixed<17, 6> v445 = v440 - v85;
    ap_fixed<17, 6> v447 = v97 + v442;
    ap_fixed<18, 8> v461 = v460 + v457;
    ap_fixed<17, 6> v462 = v456 + v458;
    ap_fixed<17, 6> v463 = v55 - v105;
    ap_fixed<17, 6> v100 = v44 - v54;
    ap_fixed<17, 6> v179 = v34 + bit_shift<-1>(inp[27]);
    ap_fixed<17, 6> v475 = v473 + v170;
    ap_fixed<17, 6> v476 = v43 + v474;
    ap_fixed<17, 6> v477 = -v87 - v178;
    ap_fixed<18, 7> v490 = v485 + v486;
    ap_fixed<18, 7> v493 = -v44 + bit_shift<1>(v62);
    ap_fixed<17, 6> v492 = v488 + v36;
    ap_fixed<18, 7> v491 = v489 + v487;
    ap_fixed<18, 7> v503 = v498 + v500;
    ap_fixed<17, 6> v504 = v501 + v55;
    ap_fixed<17, 6> v505 = -v94 + v502;
    ap_fixed<17, 6> v513 = v511 + v140;
    ap_fixed<17, 6> v515 = -v38 + v74;
    ap_fixed<18, 7> v514 = v512 + v160;
    ap_fixed<17, 6> v516 = -v89 + v117;
    ap_fixed<17, 7> v530 = v524 - bit_shift<1>(v155);
    ap_fixed<17, 6> v533 = v72 - v75;
    ap_fixed<17, 6> v534 = v529 - v163;
    ap_fixed<17, 6> v531 = v526 + v527;
    ap_fixed<18, 7> v532 = v525 + v528;
    ap_fixed<17, 6> v535 = v169 - v178;
    ap_fixed<17, 6> v546 = v545 - bit_shift<1>(v99);
    ap_fixed<17, 6> v548 = v83 + v86;
    ap_fixed<18, 7> v549 = v543 + v87;
    ap_fixed<18, 7> v547 = v544 - v70;
    ap_fixed<17, 6> v561 = v557 + v559;
    ap_fixed<17, 6> v563 = v558 - v166;
    ap_fixed<17, 6> v562 = -v61 - v94;
    ap_fixed<18, 7> v576 = v572 + v573;
    ap_fixed<17, 6> v577 = v574 - v74;
    ap_fixed<17, 6> v578 = -v84 + v86;
    ap_fixed<17, 6> v579 = -v159 + v177;
    ap_fixed<19, 8> v591 = v587 + v182;
    ap_fixed<18, 7> v595 = v590 + v136;
    ap_fixed<17, 6> v592 = v586 + v588;
    ap_fixed<17, 6> v593 = -v52 + v589;
    ap_fixed<17, 6> v594 = -v94 + v113;
    ap_fixed<18, 7> v608 = v603 + v607;
    ap_fixed<18, 7> v609 = v604 - v160;
    ap_fixed<17, 6> v610 = v605 + v606;
    ap_fixed<17, 6> v611 = -v64 + v82;
    ap_fixed<17, 6> v612 = -v90 + v113;
    ap_fixed<18, 7> v623 = v620 + v621;
    ap_fixed<17, 6> v624 = -v63 + v622;
    ap_fixed<17, 6> v625 = v116 - v120;
    // ========================== Latency: 4 ==========================
    ap_fixed<18, 7> v193 = v190 + v93;
    ap_fixed<18, 7> v194 = v191 + v192;
    ap_fixed<19, 8> v195 = v189 - v176;
    ap_fixed<18, 7> v212 = v209 + v204;
    ap_fixed<19, 8> v213 = v207 + v208;
    ap_fixed<18, 7> v214 = v210 + v211;
    ap_fixed<19, 8> v231 = v227 + v228;
    ap_fixed<18, 7> v232 = v229 + v230;
    ap_fixed<18, 7> v247 = v242 + v245;
    ap_fixed<19, 8> v246 = v244 + v243;
    ap_fixed<18, 7> v248 = -v122 - v167;
    ap_fixed<18, 7> v261 = v259 + v256;
    ap_fixed<19, 8> v262 = v258 + v260;
    ap_fixed<18, 7> v263 = v114 + v154;
    ap_fixed<19, 8> v277 = v274 + v273;
    ap_fixed<18, 7> v278 = v275 + v276;
    ap_fixed<18, 7> v279 = -v173 + v180;
    ap_fixed<19, 8> v291 = v288 + v289;
    ap_fixed<18, 7> v128 = v91 + v92;
    ap_fixed<18, 8> v307 = v302 + v304;
    ap_fixed<19, 8> v308 = v305 - v122;
    ap_fixed<18, 7> v306 = v303 + v301;
    ap_fixed<18, 7> v324 = v318 + v321;
    ap_fixed<19, 8> v325 = v320 + v319;
    ap_fixed<18, 7> v326 = v322 + v323;
    ap_fixed<18, 7> v340 = v332 + v335;
    ap_fixed<19, 8> v341 = v336 + v337;
    ap_fixed<18, 7> v342 = v338 + v339;
    ap_fixed<18, 7> v355 = v351 + v353;
    ap_fixed<18, 7> v356 = v354 - v180;
    ap_fixed<18, 7> v181 = bit_shift<-3>(inp[32]) + v95;
    ap_fixed<19, 8> v367 = v364 + v165;
    ap_fixed<18, 7> v368 = v365 + v366;
    ap_fixed<18, 7> v369 = v132 - v143;
    ap_fixed<18, 7> v157 = v59 + v111;
    ap_fixed<19, 8> v383 = v380 + v382;
    ap_fixed<18, 7> v384 = v381 + v101;
    ap_fixed<18, 7> v385 = -v151 - v164;
    ap_fixed<19, 8> v398 = v394 + v395;
    ap_fixed<18, 7> v399 = v396 + v397;
    ap_fixed<18, 7> v415 = v413 - v152;
    ap_fixed<19, 8> v416 = v411 + v412;
    ap_fixed<19, 8> v430 = v426 + v425;
    ap_fixed<18, 7> v431 = v427 + v428;
    ap_fixed<18, 7> v432 = -v149 + v429;
    ap_fixed<19, 8> v448 = v443 - v120;
    ap_fixed<18, 7> v449 = v444 + v445;
    ap_fixed<18, 7> v450 = v447 + v143;
    ap_fixed<18, 7> v464 = v462 + v459;
    ap_fixed<18, 7> v465 = v463 - v100;
    ap_fixed<18, 7> v466 = -v154 + v179;
    ap_fixed<19, 8> v478 = v472 + v475;
    ap_fixed<18, 7> v479 = v476 + v477;
    ap_fixed<18, 7> v480 = v100 - v176;
    ap_fixed<19, 8> v494 = v490 + v493;
    ap_fixed<19, 8> v495 = v492 + v491;
    ap_fixed<18, 7> v506 = v503 - v165;
    ap_fixed<18, 7> v507 = v504 + v505;
    ap_fixed<18, 7> v517 = v513 - v152;
    ap_fixed<19, 8> v518 = v515 + v514;
    ap_fixed<18, 7> v519 = v516 - v179;
    ap_fixed<17, 7> v536 = v530 - bit_shift<1>(v168);
    ap_fixed<18, 7> v538 = v533 + v534;
    ap_fixed<19, 8> v537 = v531 + v532;
    ap_fixed<18, 7> v551 = v546 + v548;
    ap_fixed<19, 8> v550 = v549 + v547;
    ap_fixed<18, 7> v552 = v114 + v167;
    ap_fixed<19, 8> v564 = v561 + v560;
    ap_fixed<18, 7> v565 = v562 - v101;
    ap_fixed<19, 8> v580 = v576 + v575;
    ap_fixed<18, 7> v581 = v577 + v578;
    ap_fixed<18, 7> v582 = v132 + v579;
    ap_fixed<20, 9> v596 = v591 + v595;
    ap_fixed<18, 7> v597 = v592 + v593;
    ap_fixed<18, 7> v598 = v594 - v164;
    ap_fixed<18, 7> v613 = v608 + v177;
    ap_fixed<19, 8> v614 = v609 + v610;
    ap_fixed<18, 7> v615 = v611 + v612;
    ap_fixed<19, 8> v626 = v623 + v619;
    ap_fixed<18, 7> v627 = v624 + v625;
    ap_fixed<18, 7> v628 = v149 - v151;
    // ========================== Latency: 5 ==========================
    ap_fixed<19, 8> v196 = v193 + v194;
    ap_fixed<20, 9> v215 = v212 + v213;
    ap_fixed<19, 8> v233 = v231 - v91;
    ap_fixed<20, 9> v249 = v247 + v246;
    ap_fixed<20, 9> v264 = v261 + v262;
    ap_fixed<20, 9> v280 = v277 + v278;
    ap_fixed<19, 8> v292 = v291 + v290;
    ap_fixed<20, 9> v309 = v307 + v308;
    ap_fixed<20, 9> v327 = v324 + v325;
    ap_fixed<20, 9> v343 = v340 + v341;
    ap_fixed<20, 9> v357 = v355 + v352;
    ap_fixed<19, 8> v358 = v356 + v181;
    ap_fixed<19, 8> v370 = v367 + v368;
    ap_fixed<19, 8> v371 = v369 - v157;
    ap_fixed<20, 9> v386 = v383 + v384;
    ap_fixed<19, 8> v400 = v398 - v98;
    ap_fixed<19, 8> v417 = v415 + v414;
    ap_fixed<20, 9> v433 = v430 + v431;
    ap_fixed<20, 9> v451 = v448 + v446;
    ap_fixed<19, 8> v452 = v449 + v450;
    ap_fixed<19, 8> v467 = v461 + v464;
    ap_fixed<19, 8> v468 = v465 + v466;
    ap_fixed<19, 8> v481 = v478 + v479;
    ap_fixed<19, 8> v496 = v494 - v173;
    ap_fixed<19, 8> v508 = v506 - v98;
    ap_fixed<19, 8> v509 = v507 - v157;
    ap_fixed<19, 8> v520 = v517 + v518;
    ap_fixed<19, 8> v540 = v536 + v538;
    ap_fixed<19, 8> v539 = v537 + v535;
    ap_fixed<20, 9> v553 = v551 + v550;
    ap_fixed<19, 8> v554 = v552 - v181;
    ap_fixed<19, 8> v566 = v564 + v563;
    ap_fixed<19, 8> v567 = v565 + v128;
    ap_fixed<20, 9> v583 = v580 + v581;
    ap_fixed<20, 9> v599 = v596 + v597;
    ap_fixed<20, 9> v616 = v613 + v614;
    ap_fixed<20, 9> v629 = v626 + v627;
    // ========================== Latency: 6 ==========================
    ap_fixed<20, 9> v197 = v196 + v195;
    ap_fixed<20, 9> v216 = v215 + v214;
    ap_fixed<20, 9> v234 = v233 + v232;
    ap_fixed<20, 9> v250 = v249 + v248;
    ap_fixed<20, 9> v265 = v264 + v263;
    ap_fixed<20, 9> v281 = v280 + v279;
    ap_fixed<20, 9> v293 = v292 - v128;
    ap_fixed<20, 9> v310 = v309 + v306;
    ap_fixed<20, 9> v328 = v327 + v326;
    ap_fixed<20, 9> v344 = v343 + v342;
    ap_fixed<20, 9> v359 = v357 + v358;
    ap_fixed<20, 9> v372 = v370 + v371;
    ap_fixed<20, 9> v387 = v386 + v385;
    ap_fixed<20, 9> v401 = v400 + v399;
    ap_fixed<20, 9> v418 = v417 + v416;
    ap_fixed<20, 9> v434 = v433 + v432;
    ap_fixed<20, 9> v453 = v451 + v452;
    ap_fixed<20, 9> v469 = v467 + v468;
    ap_fixed<20, 9> v482 = v481 + v480;
    ap_fixed<20, 9> v497 = v496 + v495;
    ap_fixed<20, 9> v510 = v508 + v509;
    ap_fixed<20, 9> v521 = v520 + v519;
    ap_fixed<20, 9> v541 = v540 + v539;
    ap_fixed<20, 9> v555 = v553 + v554;
    ap_fixed<20, 9> v568 = v566 + v567;
    ap_fixed<20, 9> v584 = v583 + v582;
    ap_fixed<20, 9> v600 = v599 + v598;
    ap_fixed<20, 9> v617 = v616 + v615;
    ap_fixed<20, 9> v630 = v629 + v628;
    // ========================== Latency: 7 ==========================
    ap_fixed<20, 9> v631 = v216 + ap_ufixed<1, -1>(0.25);
    ap_fixed<20, 9> v632 = v234 + ap_fixed<1, -2>(-0.125);
    ap_fixed<20, 9> v633 = v250 + ap_ufixed<1, -2>(0.125);
    ap_fixed<20, 9> v634 = v265 + ap_ufixed<2, -1>(0.375);
    ap_fixed<20, 9> v635 = v281 + ap_ufixed<1, -1>(0.25);
    ap_fixed<20, 9> v636 = v310 + ap_ufixed<1, -1>(0.25);
    ap_fixed<20, 9> v637 = v328 + ap_fixed<1, -2>(-0.125);
    ap_fixed<20, 9> v638 = v344 + ap_ufixed<1, -1>(0.25);
    ap_fixed<20, 9> v639 = v387 + ap_ufixed<1, -1>(0.25);
    ap_fixed<20, 9> v640 = v401 + ap_ufixed<1, -2>(0.125);
    ap_fixed<20, 9> v641 = v418 + ap_fixed<1, -2>(-0.125);
    ap_fixed<20, 9> v642 = v453 + ap_ufixed<1, -2>(0.125);
    ap_fixed<20, 9> v643 = v469 + ap_fixed<1, -2>(-0.125);
    ap_fixed<20, 9> v644 = v482 + ap_fixed<1, -2>(-0.125);
    ap_fixed<20, 9> v645 = v497 + ap_ufixed<1, -2>(0.125);
    ap_fixed<20, 9> v646 = v541 + ap_ufixed<1, -1>(0.25);
    ap_fixed<20, 9> v647 = v555 + ap_ufixed<1, -2>(0.125);
    ap_fixed<20, 9> v648 = v584 + ap_ufixed<1, -2>(0.125);
    ap_fixed<20, 9> v649 = v600 + ap_ufixed<1, -1>(0.25);
    ap_fixed<20, 9> v650 = v617 + ap_ufixed<1, -2>(0.125);
    ap_fixed<20, 9> v651 = v630 + ap_fixed<1, -2>(-0.125);
    out[0] = v197;
    out[1] = v631;
    out[2] = v632;
    out[3] = v633;
    out[4] = v634;
    out[5] = v635;
    out[6] = v293;
    out[7] = v636;
    out[8] = v637;
    out[9] = v638;
    out[10] = v359;
    out[11] = v372;
    out[12] = v639;
    out[13] = v640;
    out[14] = v641;
    out[15] = v434;
    out[16] = v642;
    out[17] = v643;
    out[18] = v644;
    out[19] = v645;
    out[20] = v510;
    out[21] = v521;
    out[22] = v646;
    out[23] = v647;
    out[24] = v568;
    out[25] = v648;
    out[26] = v649;
    out[27] = v650;
    out[28] = v651;
}
template <typename inp_t, typename out_t>
void dense_da_7(inp_t inp[29], out_t out[10]) {
    #pragma HLS INLINE
    // ========================== Latency: 1 ==========================
    ap_fixed<12, 6> v53 = -bit_shift<-2>(inp[1]) - bit_shift<-2>(inp[16]);
    ap_ufixed<11, 4> v27 = bit_shift<-3>(inp[18]) + bit_shift<-3>(inp[28]);
    ap_fixed<13, 7> v54 = -bit_shift<-1>(inp[14]) - bit_shift<-2>(inp[21]);
    ap_ufixed<12, 5> v42 = bit_shift<-3>(inp[23]) + bit_shift<-2>(inp[9]);
    ap_ufixed<11, 4> v19 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[8]);
    ap_ufixed<11, 4> v6 = bit_shift<-3>(inp[6]) + bit_shift<-3>(inp[20]);
    ap_fixed<11, 4> v7 = bit_shift<-3>(inp[3]) - bit_shift<-3>(inp[12]);
    ap_ufixed<11, 4> v16 = bit_shift<-3>(inp[5]) + bit_shift<-3>(inp[24]);
    ap_ufixed<11, 4> v18 = bit_shift<-3>(inp[14]) + bit_shift<-3>(inp[17]);
    ap_fixed<11, 4> v14 = bit_shift<-3>(inp[19]) - bit_shift<-3>(inp[22]);
    ap_fixed<11, 4> v28 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[7]);
    ap_ufixed<11, 4> v5 = bit_shift<-3>(inp[9]) + bit_shift<-3>(inp[26]);
    ap_ufixed<11, 4> v13 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[11]);
    ap_fixed<11, 4> v66 = bit_shift<-3>(inp[13]) - bit_shift<-3>(inp[19]);
    ap_fixed<11, 6> v68 = bit_shift<-1>(inp[22]) - bit_shift<-1>(inp[27]);
    ap_fixed<11, 4> v1 = bit_shift<-3>(inp[8]) - bit_shift<-3>(inp[16]);
    ap_ufixed<11, 4> v2 = bit_shift<-3>(inp[27]) + bit_shift<-3>(inp[28]);
    ap_ufixed<11, 4> v67 = bit_shift<-3>(inp[21]) + bit_shift<-3>(inp[26]);
    ap_ufixed<12, 5> v40 = bit_shift<-3>(inp[12]) + bit_shift<-2>(inp[5]);
    ap_ufixed<11, 4> v0 = bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[4]);
    ap_ufixed<11, 4> v11 = bit_shift<-3>(inp[10]) + bit_shift<-3>(inp[23]);
    ap_fixed<11, 4> v78 = -bit_shift<-3>(inp[3]) + bit_shift<-3>(inp[5]);
    ap_ufixed<12, 5> v80 = bit_shift<-3>(inp[20]) + bit_shift<-2>(inp[26]);
    ap_fixed<11, 5> v79 = bit_shift<-2>(inp[8]) - bit_shift<-2>(inp[14]);
    ap_fixed<11, 4> v32 = bit_shift<-3>(inp[11]) - bit_shift<-3>(inp[16]);
    ap_ufixed<11, 4> v12 = bit_shift<-3>(inp[7]) + bit_shift<-3>(inp[13]);
    ap_fixed<11, 4> v3 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[12]);
    ap_ufixed<11, 4> v10 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[22]);
    ap_fixed<11, 4> v9 = bit_shift<-3>(inp[17]) - bit_shift<-3>(inp[21]);
    ap_ufixed<11, 4> v29 = bit_shift<-3>(inp[9]) + bit_shift<-3>(inp[25]);
    ap_fixed<12, 6> v91 = -bit_shift<-2>(inp[0]) - bit_shift<-2>(inp[24]);
    ap_fixed<14, 7> v93 = -bit_shift<-3>(inp[15]) - bit_shift<-1>(inp[16]);
    ap_fixed<12, 7> v92 = -bit_shift<-1>(inp[4]) - bit_shift<-1>(inp[7]);
    ap_ufixed<11, 4> v8 = bit_shift<-3>(inp[11]) + bit_shift<-3>(inp[18]);
    ap_fixed<11, 4> v15 = bit_shift<-3>(inp[4]) - bit_shift<-3>(inp[20]);
    ap_fixed<11, 5> v103 = bit_shift<-2>(inp[1]) - bit_shift<-2>(inp[7]);
    ap_fixed<11, 4> v33 = bit_shift<-3>(inp[10]) - bit_shift<-3>(inp[23]);
    ap_ufixed<13, 6> v104 = bit_shift<-1>(inp[10]) + bit_shift<-3>(inp[13]);
    ap_ufixed<11, 4> v21 = bit_shift<-3>(inp[5]) + bit_shift<-3>(inp[25]);
    ap_ufixed<11, 4> v34 = bit_shift<-3>(inp[13]) + bit_shift<-3>(inp[19]);
    ap_fixed<12, 5> v126 = -bit_shift<-3>(inp[7]) - bit_shift<-3>(inp[10]);
    ap_ufixed<11, 4> v4 = bit_shift<-3>(inp[15]) + bit_shift<-3>(inp[24]);
    ap_fixed<12, 5> v135 = -bit_shift<-3>(inp[3]) - bit_shift<-3>(inp[6]);
    ap_ufixed<13, 6> v137 = bit_shift<-3>(inp[9]) + bit_shift<-1>(inp[16]);
    ap_ufixed<11, 5> v136 = bit_shift<-2>(inp[20]) + bit_shift<-2>(inp[22]);
    ap_fixed<12, 5> v147 = -bit_shift<-3>(inp[6]) - bit_shift<-3>(inp[9]);
    ap_ufixed<11, 4> v30 = bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[25]);
    ap_fixed<12, 6> v148 = -bit_shift<-2>(inp[17]) - bit_shift<-2>(inp[26]);
    ap_fixed<11, 5> v159 = bit_shift<-2>(inp[2]) - bit_shift<-2>(inp[7]);
    ap_ufixed<11, 5> v161 = bit_shift<-2>(inp[16]) + bit_shift<-2>(inp[19]);
    ap_fixed<11, 4> v160 = -bit_shift<-3>(inp[3]) + bit_shift<-3>(inp[11]);
    // ========================== Latency: 2 ==========================
    ap_fixed<12, 6> v56 = v53 + bit_shift<1>(v27);
    ap_fixed<14, 8> v55 = v54 - bit_shift<1>(v42);
    ap_ufixed<12, 5> v25 = bit_shift<-3>(inp[15]) + v6;
    ap_fixed<12, 5> v57 = -v16 + v18;
    ap_fixed<12, 6> v58 = bit_shift<1>(v14) + bit_shift<1>(v28);
    ap_fixed<12, 5> v37 = v5 - v13;
    ap_fixed<13, 6> v70 = v66 + v13;
    ap_fixed<13, 6> v48 = bit_shift<-3>(inp[22]) - bit_shift<1>(v6);
    ap_fixed<13, 6> v38 = v1 - v2;
    ap_ufixed<12, 5> v69 = v67 + bit_shift<-2>(inp[25]);
    ap_fixed<14, 7> v45 = v16 - bit_shift<1>(v40);
    ap_fixed<12, 5> v22 = bit_shift<-3>(inp[0]) - v0;
    ap_ufixed<13, 6> v31 = v11 + bit_shift<1>(v5);
    ap_fixed<14, 7> v83 = v78 + bit_shift<1>(v42);
    ap_ufixed<13, 6> v81 = v80 + bit_shift<-1>(inp[28]);
    ap_fixed<12, 6> v82 = v79 - bit_shift<1>(v32);
    ap_ufixed<12, 5> v47 = bit_shift<-3>(inp[28]) + v12;
    ap_fixed<13, 6> v24 = v3 - v10;
    ap_fixed<12, 5> v23 = bit_shift<-3>(inp[24]) + v9;
    ap_fixed<12, 5> v44 = bit_shift<-3>(inp[18]) - v29;
    ap_fixed<15, 8> v94 = v91 + v93;
    ap_fixed<15, 8> v96 = v92 - v14;
    ap_ufixed<12, 5> v26 = bit_shift<-3>(inp[1]) + v2;
    ap_fixed<13, 6> v95 = bit_shift<1>(v9) + v12;
    ap_fixed<12, 5> v20 = v1 - v7;
    ap_fixed<13, 6> v35 = v8 - v15;
    ap_fixed<13, 6> v107 = v103 + v8;
    ap_fixed<12, 5> v108 = v1 + v15;
    ap_fixed<14, 7> v105 = v104 - bit_shift<1>(v2);
    ap_ufixed<12, 6> v106 = bit_shift<1>(v5) + bit_shift<1>(v21);
    ap_fixed<12, 6> v116 = -bit_shift<-2>(inp[5]) + bit_shift<1>(v2);
    ap_fixed<13, 7> v117 = -bit_shift<2>(v0) + bit_shift<1>(v10);
    ap_ufixed<12, 5> v43 = bit_shift<-3>(inp[23]) + v0;
    ap_fixed<13, 6> v118 = bit_shift<1>(v9) + v28;
    ap_fixed<13, 6> v127 = v126 - bit_shift<-2>(inp[27]);
    ap_ufixed<12, 5> v17 = bit_shift<-3>(inp[14]) + v4;
    ap_fixed<14, 7> v138 = v135 + v137;
    ap_ufixed<13, 6> v140 = bit_shift<1>(v11) + v12;
    ap_ufixed<12, 6> v139 = v136 + bit_shift<1>(v8);
    ap_fixed<12, 5> v149 = v147 + v30;
    ap_fixed<12, 5> v151 = -v7 - v14;
    ap_fixed<13, 7> v150 = v148 - bit_shift<1>(v1);
    ap_fixed<15, 8> v152 = -bit_shift<2>(v30) + v33;
    ap_fixed<14, 8> v165 = v159 - bit_shift<2>(v21);
    ap_ufixed<12, 6> v162 = bit_shift<-1>(inp[8]) + v161;
    ap_fixed<12, 5> v164 = v160 - v3;
    ap_fixed<12, 5> v163 = -v19 + v21;
    // ========================== Latency: 3 ==========================
    ap_fixed<14, 8> v60 = v56 + v55;
    ap_ufixed<13, 6> v46 = v19 + v25;
    ap_fixed<13, 6> v59 = v7 + v57;
    ap_fixed<14, 7> v61 = v58 + v37;
    ap_fixed<14, 7> v71 = v70 + v68;
    ap_fixed<14, 7> v49 = v38 + bit_shift<1>(v18);
    ap_fixed<15, 8> v72 = v69 - v45;
    ap_fixed<15, 9> v73 = -bit_shift<2>(v22) + bit_shift<1>(v31);
    ap_fixed<15, 8> v84 = v83 + v81;
    ap_fixed<14, 7> v85 = v82 - v47;
    ap_fixed<14, 7> v36 = v0 - v24;
    ap_fixed<13, 6> v86 = -v23 + v44;
    ap_fixed<16, 9> v97 = v94 + v96;
    ap_fixed<14, 7> v98 = v95 - v31;
    ap_fixed<14, 7> v99 = -v20 - v35;
    ap_fixed<14, 7> v109 = v107 - v33;
    ap_fixed<13, 6> v111 = v108 + v23;
    ap_fixed<15, 8> v110 = v105 + v106;
    ap_fixed<15, 8> v112 = -bit_shift<2>(v23) + v24;
    ap_fixed<13, 7> v119 = v116 - bit_shift<2>(v32);
    ap_fixed<14, 7> v121 = v117 + v43;
    ap_fixed<14, 7> v120 = v118 - v25;
    ap_fixed<14, 7> v52 = v20 - bit_shift<1>(v34);
    ap_fixed<14, 7> v128 = v127 + bit_shift<2>(v3);
    ap_fixed<14, 8> v129 = -bit_shift<1>(v37) - bit_shift<1>(v43);
    ap_ufixed<12, 5> v39 = bit_shift<-3>(inp[21]) + v17;
    ap_fixed<15, 8> v141 = v138 + v140;
    ap_fixed<15, 8> v142 = v139 - v45;
    ap_fixed<13, 6> v41 = bit_shift<-3>(inp[26]) - v22;
    ap_fixed<13, 6> v154 = v149 + v151;
    ap_fixed<14, 7> v50 = v17 - bit_shift<2>(v4);
    ap_fixed<15, 8> v153 = v150 + v152;
    ap_fixed<14, 7> v155 = v35 - bit_shift<1>(v47);
    ap_fixed<14, 8> v166 = v165 + v162;
    ap_fixed<13, 6> v168 = v164 + v163;
    ap_fixed<14, 7> v167 = bit_shift<1>(v26) - v31;
    // ========================== Latency: 4 ==========================
    ap_fixed<16, 10> v63 = v60 - bit_shift<2>(v46);
    ap_fixed<15, 8> v62 = v61 + v46;
    ap_fixed<15, 8> v74 = v71 - v48;
    ap_fixed<16, 9> v75 = v72 + v73;
    ap_fixed<16, 9> v87 = v84 + v85;
    ap_fixed<15, 8> v88 = v86 - v36;
    ap_fixed<16, 9> v100 = v97 - bit_shift<1>(v26);
    ap_fixed<15, 8> v101 = v98 + v99;
    ap_fixed<15, 8> v114 = v109 + v111;
    ap_fixed<16, 9> v113 = v110 + v112;
    ap_fixed<15, 8> v122 = v121 + v44;
    ap_fixed<15, 8> v123 = v120 + v52;
    ap_fixed<15, 8> v130 = v128 - v48;
    ap_fixed<15, 8> v131 = v129 + v52;
    ap_ufixed<13, 6> v51 = v27 + v39;
    ap_fixed<16, 9> v143 = v141 + v142;
    ap_fixed<14, 7> v144 = -v41 + v49;
    ap_fixed<15, 8> v157 = v154 + v50;
    ap_fixed<16, 9> v156 = v153 + v155;
    ap_fixed<15, 8> v170 = v166 + v168;
    ap_fixed<15, 8> v169 = v167 - v50;
    // ========================== Latency: 5 ==========================
    ap_fixed<15, 8> v64 = v59 + v62;
    ap_fixed<15, 8> v76 = v74 - v49;
    ap_fixed<17, 10> v89 = v87 + bit_shift<2>(v36);
    ap_fixed<17, 10> v102 = v100 + v101;
    ap_fixed<16, 9> v115 = v114 + v113;
    ap_fixed<15, 8> v124 = v119 + v122;
    ap_fixed<16, 9> v132 = v130 + v131;
    ap_fixed<16, 9> v133 = -v51 + bit_shift<2>(v51);
    ap_fixed<17, 10> v145 = v143 + bit_shift<2>(v41);
    ap_fixed<17, 10> v158 = v157 + v156;
    ap_fixed<16, 9> v171 = v170 + v169;
    // ========================== Latency: 6 ==========================
    ap_fixed<17, 10> v65 = v63 + v64;
    ap_fixed<17, 10> v77 = v76 + v75;
    ap_fixed<17, 10> v90 = v89 + v88;
    ap_fixed<17, 10> v175 = v102 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v176 = v115 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v125 = v124 + v123;
    ap_fixed<17, 10> v134 = v132 + v133;
    ap_fixed<17, 10> v146 = v145 + v144;
    ap_fixed<17, 10> v180 = v158 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v181 = v171 + ap_fixed<1, -2>(-0.125);
    // ========================== Latency: 7 ==========================
    ap_fixed<17, 10> v172 = v65 + ap_fixed<1, -2>(-0.125);
    ap_fixed<17, 10> v173 = v77 + ap_ufixed<2, -1>(0.375);
    ap_fixed<17, 10> v174 = v90 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v177 = v125 + ap_fixed<1, -2>(-0.125);
    ap_fixed<17, 10> v178 = v134 + ap_fixed<1, -2>(-0.125);
    ap_fixed<17, 10> v179 = v146 + ap_fixed<1, -2>(-0.125);
    out[0] = v172;
    out[1] = v173;
    out[2] = v174;
    out[3] = v175;
    out[4] = v176;
    out[5] = v177;
    out[6] = v178;
    out[7] = v179;
    out[8] = v180;
    out[9] = v181;
}
template <typename inp_t, typename out_t>
void dense_da_11(inp_t inp[10], out_t out[9]) {
    #pragma HLS INLINE
    // ========================== Latency: 1 ==========================
    ap_fixed<11, 4> v13 = bit_shift<-3>(inp[2]) - bit_shift<-3>(inp[6]);
    ap_fixed<11, 4> v2 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[9]);
    ap_fixed<13, 6> v14 = -bit_shift<-1>(inp[2]) + bit_shift<-3>(inp[7]);
    ap_ufixed<12, 5> v8 = bit_shift<-3>(inp[3]) + bit_shift<-2>(inp[4]);
    ap_ufixed<11, 4> v1 = bit_shift<-3>(inp[0]) + bit_shift<-3>(inp[8]);
    ap_fixed<12, 5> v3 = bit_shift<-3>(inp[1]) - bit_shift<-2>(inp[3]);
    ap_ufixed<11, 4> v20 = bit_shift<-3>(inp[6]) + bit_shift<-3>(inp[7]);
    ap_ufixed<11, 4> v4 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[3]);
    ap_ufixed<11, 4> v0 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[9]);
    ap_fixed<12, 5> v11 = bit_shift<-3>(inp[0]) - bit_shift<-2>(inp[8]);
    ap_fixed<14, 7> v26 = bit_shift<-3>(inp[1]) - inp[6];
    ap_fixed<12, 7> v25 = -bit_shift<-1>(inp[1]) - bit_shift<-1>(inp[5]);
    ap_fixed<11, 4> v5 = bit_shift<-3>(inp[5]) - bit_shift<-3>(inp[6]);
    ap_ufixed<11, 6> v31 = bit_shift<-1>(inp[7]) + bit_shift<-1>(inp[9]);
    ap_ufixed<12, 5> v36 = bit_shift<-3>(inp[0]) + bit_shift<-2>(inp[8]);
    ap_fixed<11, 4> v7 = bit_shift<-3>(inp[2]) - bit_shift<-3>(inp[7]);
    ap_ufixed<11, 4> v6 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[4]);
    ap_ufixed<11, 5> v41 = bit_shift<-2>(inp[6]) + bit_shift<-2>(inp[9]);
    ap_fixed<11, 6> v46 = bit_shift<-1>(inp[3]) - bit_shift<-1>(inp[8]);
    ap_fixed<12, 6> v51 = -bit_shift<-2>(inp[5]) - bit_shift<-2>(inp[8]);
    ap_fixed<12, 5> v55 = -bit_shift<-2>(inp[5]) + bit_shift<-3>(inp[7]);
    // ========================== Latency: 2 ==========================
    ap_fixed<12, 5> v16 = v13 - v2;
    ap_fixed<14, 7> v15 = v14 - v8;
    ap_fixed<14, 8> v17 = bit_shift<2>(v1) + bit_shift<1>(v3);
    ap_fixed<12, 5> v21 = v20 - v4;
    ap_fixed<12, 5> v12 = v0 - bit_shift<-2>(inp[1]);
    ap_fixed<14, 8> v22 = bit_shift<2>(v0) + bit_shift<1>(v11);
    ap_fixed<15, 8> v27 = v26 + v25;
    ap_fixed<15, 8> v28 = bit_shift<2>(v4) - v5;
    ap_fixed<14, 7> v10 = v0 - bit_shift<2>(v1);
    ap_fixed<12, 5> v32 = bit_shift<-2>(inp[6]) - v1;
    ap_fixed<15, 8> v33 = v31 + v3;
    ap_fixed<13, 6> v37 = v36 - bit_shift<-1>(inp[0]);
    ap_fixed<12, 6> v38 = -bit_shift<1>(v5) - bit_shift<1>(v7);
    ap_fixed<13, 6> v42 = -bit_shift<-3>(inp[5]) - v6;
    ap_ufixed<13, 7> v43 = v41 + bit_shift<2>(v4);
    ap_fixed<13, 7> v48 = v46 - bit_shift<1>(v7);
    ap_fixed<12, 5> v47 = bit_shift<-3>(inp[8]) - v2;
    ap_fixed<13, 6> v52 = bit_shift<-3>(inp[6]) - v8;
    ap_fixed<13, 6> v9 = v3 - bit_shift<-2>(inp[7]);
    ap_fixed<13, 6> v56 = v55 + v6;
    ap_fixed<14, 7> v57 = v2 - bit_shift<2>(v2);
    // ========================== Latency: 3 ==========================
    ap_fixed<15, 8> v18 = v15 + v17;
    ap_fixed<13, 6> v23 = v21 - v12;
    ap_fixed<16, 9> v29 = v27 + v28;
    ap_fixed<16, 9> v34 = v33 - v10;
    ap_fixed<14, 7> v39 = v37 + v38;
    ap_fixed<14, 7> v44 = v42 + v11;
    ap_fixed<13, 6> v49 = v47 + v5;
    ap_fixed<14, 7> v53 = v51 + v52;
    ap_fixed<14, 7> v58 = v56 + v57;
    // ========================== Latency: 4 ==========================
    ap_fixed<15, 8> v19 = v16 + v18;
    ap_fixed<15, 8> v24 = v23 + v22;
    ap_fixed<16, 9> v30 = v29 - v10;
    ap_fixed<16, 9> v35 = v32 + v34;
    ap_fixed<15, 8> v40 = v39 + v12;
    ap_fixed<15, 8> v45 = v44 + v43;
    ap_fixed<15, 8> v50 = v48 + v49;
    ap_fixed<15, 8> v54 = v53 - bit_shift<1>(v9);
    ap_fixed<15, 8> v59 = v58 + bit_shift<1>(v9);
    // ========================== Latency: 5 ==========================
    ap_fixed<15, 8> v60 = v19 + ap_ufixed<2, -1>(0.375);
    ap_fixed<15, 8> v61 = v24 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v62 = v30 + ap_fixed<1, -1>(-0.25);
    ap_fixed<15, 8> v63 = v40 + ap_ufixed<2, 0>(0.75);
    ap_fixed<15, 8> v64 = v45 + ap_fixed<1, -1>(-0.25);
    ap_fixed<15, 8> v65 = v50 + ap_ufixed<1, -1>(0.25);
    ap_fixed<15, 8> v66 = v54 + ap_ufixed<2, -1>(0.375);
    ap_fixed<15, 8> v67 = v59 + ap_ufixed<1, -2>(0.125);
    out[0] = v60;
    out[1] = v61;
    out[2] = v62;
    out[3] = v35;
    out[4] = v63;
    out[5] = v64;
    out[6] = v65;
    out[7] = v66;
    out[8] = v67;
}
template <typename inp_t, typename out_t>
void dense_da_15(inp_t inp[9], out_t out[6]) {
    #pragma HLS INLINE
    // ========================== Latency: 1 ==========================
    ap_ufixed<12, 6> v11 = bit_shift<-2>(inp[2]) + bit_shift<-1>(inp[5]);
    ap_ufixed<12, 5> v9 = bit_shift<-3>(inp[5]) + bit_shift<-2>(inp[4]);
    ap_fixed<11, 4> v2 = bit_shift<-3>(inp[3]) - bit_shift<-3>(inp[7]);
    ap_fixed<12, 5> v3 = bit_shift<-3>(inp[0]) - bit_shift<-2>(inp[1]);
    ap_ufixed<12, 5> v15 = bit_shift<-3>(inp[3]) + bit_shift<-2>(inp[7]);
    ap_ufixed<13, 6> v10 = bit_shift<-3>(inp[5]) + bit_shift<-1>(inp[4]);
    ap_fixed<12, 5> v6 = bit_shift<-3>(inp[2]) - bit_shift<-2>(inp[8]);
    ap_fixed<14, 7> v20 = -bit_shift<-3>(inp[1]) - bit_shift<-1>(inp[4]);
    ap_ufixed<11, 5> v19 = bit_shift<-2>(inp[5]) + bit_shift<-2>(inp[6]);
    ap_ufixed<11, 4> v1 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[3]);
    ap_fixed<11, 4> v5 = bit_shift<-3>(inp[7]) - bit_shift<-3>(inp[8]);
    ap_fixed<11, 4> v0 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[1]);
    ap_ufixed<11, 4> v4 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[6]);
    ap_ufixed<12, 7> v29 = inp[4] + bit_shift<-1>(inp[6]);
    ap_fixed<13, 6> v30 = -bit_shift<-2>(inp[5]) - bit_shift<-3>(inp[7]);
    ap_fixed<14, 7> v36 = inp[1] - bit_shift<-3>(inp[8]);
    // ========================== Latency: 2 ==========================
    ap_fixed<14, 7> v12 = v11 - v9;
    ap_fixed<12, 5> v8 = bit_shift<-3>(inp[6]) + v3;
    ap_ufixed<13, 6> v16 = v15 + v10;
    ap_fixed<14, 7> v21 = v20 + v19;
    ap_fixed<14, 7> v22 = -v1 - bit_shift<2>(v5);
    ap_fixed<13, 6> v7 = v0 - v1;
    ap_fixed<13, 7> v26 = bit_shift<2>(v0) - bit_shift<1>(v5);
    ap_fixed<14, 7> v25 = -v4 - v10;
    ap_fixed<13, 8> v32 = v29 + bit_shift<2>(v2);
    ap_fixed<14, 7> v31 = v30 - v4;
    ap_fixed<13, 7> v33 = bit_shift<1>(v0) + bit_shift<1>(v6);
    ap_fixed<14, 7> v37 = v36 - bit_shift<1>(v9);
    ap_fixed<13, 6> v38 = v3 - v4;
    // ========================== Latency: 3 ==========================
    ap_fixed<15, 8> v13 = v12 + bit_shift<2>(v2);
    ap_fixed<15, 8> v17 = v16 - bit_shift<1>(v6);
    ap_fixed<15, 8> v23 = v21 + v22;
    ap_fixed<15, 8> v27 = v26 + v25;
    ap_fixed<15, 8> v34 = v31 + v33;
    ap_fixed<15, 8> v39 = v37 - v2;
    // ========================== Latency: 4 ==========================
    ap_fixed<15, 8> v14 = v13 + bit_shift<1>(v8);
    ap_fixed<15, 8> v18 = v17 + bit_shift<1>(v8);
    ap_fixed<16, 9> v24 = v23 + bit_shift<2>(v7);
    ap_fixed<15, 8> v28 = v27 - v7;
    ap_fixed<16, 9> v35 = v32 + v34;
    ap_fixed<15, 8> v40 = v39 + v38;
    // ========================== Latency: 5 ==========================
    ap_fixed<15, 8> v41 = v14 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v42 = v18 + ap_ufixed<2, -1>(0.375);
    ap_fixed<16, 9> v43 = v35 + ap_ufixed<1, -1>(0.25);
    ap_fixed<15, 8> v44 = v40 + ap_ufixed<1, -2>(0.125);
    out[0] = v41;
    out[1] = v42;
    out[2] = v24;
    out[3] = v28;
    out[4] = v43;
    out[5] = v44;
}
template <typename inp_t, typename out_t>
void dense_da_19(inp_t inp[6], out_t out[4]) {
    #pragma HLS INLINE
    // ========================== Latency: 1 ==========================
    ap_fixed<12, 5> v3 = -bit_shift<-3>(inp[3]) + bit_shift<-2>(inp[4]);
    ap_fixed<12, 5> v2 = bit_shift<-3>(inp[5]) - bit_shift<-2>(inp[1]);
    ap_ufixed<11, 4> v0 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[3]);
    ap_ufixed<11, 4> v7 = bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[4]);
    ap_fixed<13, 6> v9 = -bit_shift<-3>(inp[1]) - bit_shift<-2>(inp[5]);
    ap_fixed<12, 5> v12 = -bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[2]);
    ap_ufixed<11, 4> v13 = bit_shift<-3>(inp[3]) + bit_shift<-3>(inp[5]);
    // ========================== Latency: 2 ==========================
    ap_fixed<13, 6> v4 = v3 + v2;
    ap_fixed<12, 5> v1 = bit_shift<-3>(inp[0]) - v0;
    ap_fixed<13, 6> v8 = v7 - bit_shift<-1>(inp[4]);
    ap_fixed<14, 7> v10 = v9 - v0;
    ap_fixed<12, 5> v14 = v12 + v13;
    // ========================== Latency: 3 ==========================
    ap_fixed<13, 8> v5 = -bit_shift<2>(v1) - bit_shift<2>(v2);
    ap_fixed<13, 6> v17 = v8 + ap_ufixed<2, -1>(0.375);
    ap_fixed<15, 8> v11 = v10 + bit_shift<2>(v1);
    ap_fixed<15, 8> v15 = v14 + bit_shift<2>(v0);
    // ========================== Latency: 4 ==========================
    ap_fixed<16, 9> v6 = v4 + v5;
    ap_fixed<15, 8> v18 = v15 + ap_fixed<1, -1>(-0.25);
    // ========================== Latency: 5 ==========================
    ap_fixed<16, 9> v16 = v6 + ap_fixed<1, -2>(-0.125);
    out[0] = v16;
    out[1] = v17;
    out[2] = v11;
    out[3] = v18;
}
template <typename inp_t, typename out_t>
void dense_da_21(inp_t inp[4], out_t out[6]) {
    #pragma HLS INLINE
    // ========================== Latency: 1 ==========================
    ap_fixed<16, 6> v1 = bit_shift<-3>(inp[0]) + bit_shift<-3>(inp[1]);
    ap_fixed<17, 7> v0 = bit_shift<-3>(inp[2]) + bit_shift<-2>(inp[3]);
    ap_fixed<16, 6> v4 = -bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[3]);
    ap_fixed<17, 9> v7 = -bit_shift<-1>(inp[2]) - bit_shift<-1>(inp[3]);
    ap_fixed<19, 9> v2 = bit_shift<-3>(inp[1]) - inp[0];
    ap_fixed<16, 6> v11 = -bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[3]);
    ap_fixed<18, 8> v14 = -bit_shift<-3>(inp[0]) - bit_shift<-1>(inp[0]);
    // ========================== Latency: 2 ==========================
    ap_fixed<18, 8> v3 = -bit_shift<-1>(inp[0]) + v1;
    ap_fixed<18, 9> v5 = -bit_shift<-1>(inp[0]) + bit_shift<1>(v0);
    ap_fixed<18, 10> v8 = -inp[0] + v7;
    ap_fixed<19, 9> v10 = v0 + v2;
    ap_fixed<19, 9> v12 = bit_shift<-1>(inp[2]) + v2;
    ap_fixed<19, 9> v15 = v14 - v0;
    // ========================== Latency: 3 ==========================
    ap_fixed<18, 8> v16 = v3 + ap_ufixed<1, 0>(0.5);
    ap_fixed<19, 9> v6 = v5 + v4;
    ap_fixed<20, 10> v9 = v8 - v1;
    ap_fixed<19, 9> v13 = v11 + v12;
    ap_fixed<19, 9> v20 = v15 + ap_ufixed<1, 0>(0.5);
    // ========================== Latency: 4 ==========================
    ap_fixed<19, 9> v17 = v6 + ap_ufixed<3, 0>(0.625);
    ap_fixed<20, 10> v18 = v9 + ap_ufixed<3, 0>(0.625);
    ap_fixed<19, 9> v19 = v13 + ap_ufixed<3, 0>(0.625);
    out[0] = v16;
    out[1] = v17;
    out[2] = v18;
    out[3] = v10;
    out[4] = v19;
    out[5] = v20;
}
template <typename inp_t, typename out_t>
void dense_da_25(inp_t inp[6], out_t out[9]) {
    #pragma HLS INLINE
    // ========================== Latency: 1 ==========================
    ap_ufixed<12, 5> v0 = bit_shift<-3>(inp[0]) + bit_shift<-2>(inp[4]);
    ap_ufixed<11, 4> v2 = bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[2]);
    ap_fixed<12, 5> v7 = bit_shift<-3>(inp[5]) - bit_shift<-2>(inp[1]);
    ap_fixed<13, 6> v12 = -bit_shift<-1>(inp[1]) + bit_shift<-3>(inp[4]);
    ap_ufixed<11, 4> v5 = bit_shift<-3>(inp[3]) + bit_shift<-3>(inp[5]);
    ap_ufixed<11, 4> v3 = bit_shift<-3>(inp[3]) + bit_shift<-3>(inp[4]);
    ap_ufixed<12, 7> v15 = bit_shift<-1>(inp[3]) + inp[5];
    ap_fixed<15, 8> v19 = -inp[0] - bit_shift<-3>(inp[5]);
    ap_fixed<11, 4> v1 = bit_shift<-3>(inp[3]) - bit_shift<-3>(inp[5]);
    ap_ufixed<12, 5> v22 = bit_shift<-3>(inp[0]) + bit_shift<-2>(inp[5]);
    ap_fixed<11, 4> v4 = bit_shift<-3>(inp[1]) - bit_shift<-3>(inp[2]);
    ap_ufixed<13, 7> v27 = bit_shift<-2>(inp[2]) + inp[4];
    ap_ufixed<13, 6> v8 = bit_shift<-3>(inp[4]) + bit_shift<-1>(inp[2]);
    ap_fixed<14, 7> v35 = -bit_shift<-3>(inp[0]) + inp[0];
    ap_fixed<11, 6> v34 = -bit_shift<-1>(inp[3]) + bit_shift<-1>(inp[4]);
    ap_fixed<12, 6> v40 = bit_shift<-2>(inp[2]) - bit_shift<-1>(inp[3]);
    // ========================== Latency: 2 ==========================
    ap_fixed<13, 6> v9 = bit_shift<-1>(inp[0]) - v0;
    ap_fixed<16, 9> v10 = bit_shift<3>(v2) + v7;
    ap_fixed<14, 7> v13 = v12 - v5;
    ap_fixed<13, 6> v16 = -bit_shift<-3>(inp[1]) - v0;
    ap_ufixed<13, 8> v17 = v15 + bit_shift<2>(v0);
    ap_fixed<15, 8> v20 = v19 + v0;
    ap_fixed<12, 5> v6 = bit_shift<-3>(inp[1]) - v1;
    ap_ufixed<13, 6> v24 = v22 + v3;
    ap_ufixed<12, 7> v23 = inp[4] + bit_shift<2>(v2);
    ap_ufixed<14, 8> v28 = v27 + bit_shift<2>(v5);
    ap_fixed<14, 7> v30 = bit_shift<1>(v0) - v8;
    ap_fixed<13, 6> v31 = v1 + v2;
    ap_fixed<14, 7> v36 = v35 - v8;
    ap_fixed<12, 5> v37 = -v1 - v4;
    ap_fixed<13, 7> v42 = v40 - bit_shift<1>(v7);
    ap_fixed<13, 7> v41 = inp[5] - bit_shift<1>(v0);
    // ========================== Latency: 3 ==========================
    ap_fixed<16, 9> v11 = v9 + v10;
    ap_fixed<15, 8> v14 = v13 - bit_shift<2>(v3);
    ap_fixed<16, 9> v18 = v16 + v17;
    ap_fixed<16, 9> v21 = v20 - bit_shift<2>(v6);
    ap_fixed<14, 7> v25 = v24 - v4;
    ap_fixed<16, 9> v29 = v28 + v6;
    ap_fixed<15, 8> v32 = v30 - bit_shift<2>(v1);
    ap_fixed<15, 8> v38 = v36 + v34;
    ap_fixed<14, 7> v43 = v42 + v3;
    // ========================== Latency: 4 ==========================
    ap_fixed<16, 9> v45 = v11 + ap_ufixed<2, -1>(0.375);
    ap_fixed<16, 9> v46 = v18 + ap_ufixed<2, -1>(0.375);
    ap_fixed<16, 9> v47 = v21 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v26 = v25 + v23;
    ap_fixed<16, 9> v49 = v29 + ap_ufixed<2, 0>(0.75);
    ap_fixed<15, 8> v33 = v32 + v31;
    ap_fixed<15, 8> v39 = v38 + v37;
    ap_fixed<15, 8> v44 = v43 + v41;
    // ========================== Latency: 5 ==========================
    ap_fixed<16, 9> v48 = v26 + ap_ufixed<2, -1>(0.375);
    ap_fixed<15, 8> v50 = v33 + ap_ufixed<1, -2>(0.125);
    ap_fixed<15, 8> v51 = v39 + ap_ufixed<2, 0>(0.75);
    ap_fixed<16, 9> v52 = v44 + ap_ufixed<1, 0>(0.5);
    out[0] = v45;
    out[1] = v14;
    out[2] = v46;
    out[3] = v47;
    out[4] = v48;
    out[5] = v49;
    out[6] = v50;
    out[7] = v51;
    out[8] = v52;
}
template <typename inp_t, typename out_t>
void dense_da_29(inp_t inp[9], out_t out[10]) {
    #pragma HLS INLINE
    // ========================== Latency: 1 ==========================
    ap_fixed<11, 6> v14 = bit_shift<-1>(inp[2]) - bit_shift<-1>(inp[5]);
    ap_ufixed<11, 4> v9 = bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[7]);
    ap_fixed<11, 4> v0 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[5]);
    ap_ufixed<13, 6> v8 = bit_shift<-3>(inp[2]) + bit_shift<-1>(inp[3]);
    ap_fixed<11, 4> v18 = -bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[2]);
    ap_fixed<11, 6> v19 = bit_shift<-1>(inp[2]) - bit_shift<-1>(inp[6]);
    ap_fixed<12, 6> v20 = -bit_shift<-2>(inp[3]) - bit_shift<-2>(inp[7]);
    ap_ufixed<14, 7> v21 = inp[4] + bit_shift<-3>(inp[5]);
    ap_fixed<11, 4> v3 = bit_shift<-3>(inp[0]) - bit_shift<-3>(inp[8]);
    ap_ufixed<11, 4> v1 = bit_shift<-3>(inp[0]) + bit_shift<-3>(inp[8]);
    ap_fixed<13, 6> v27 = -bit_shift<-2>(inp[4]) - bit_shift<-3>(inp[8]);
    ap_fixed<12, 5> v2 = bit_shift<-3>(inp[7]) - bit_shift<-2>(inp[1]);
    ap_ufixed<11, 4> v7 = bit_shift<-3>(inp[2]) + bit_shift<-3>(inp[6]);
    ap_fixed<13, 6> v33 = -bit_shift<-2>(inp[3]) - bit_shift<-3>(inp[6]);
    ap_fixed<11, 6> v36 = bit_shift<-1>(inp[3]) - bit_shift<-1>(inp[8]);
    ap_fixed<11, 4> v10 = bit_shift<-3>(inp[4]) - bit_shift<-3>(inp[6]);
    ap_ufixed<11, 4> v4 = bit_shift<-3>(inp[4]) + bit_shift<-3>(inp[6]);
    ap_fixed<13, 6> v42 = -bit_shift<-3>(inp[5]) + bit_shift<-1>(inp[5]);
    ap_fixed<11, 5> v46 = -bit_shift<-2>(inp[2]) + bit_shift<-2>(inp[8]);
    ap_fixed<13, 6> v47 = bit_shift<-3>(inp[4]) - bit_shift<-1>(inp[6]);
    ap_ufixed<12, 7> v51 = bit_shift<-1>(inp[4]) + inp[7];
    ap_fixed<12, 6> v56 = -bit_shift<-2>(inp[6]) - bit_shift<-2>(inp[8]);
    ap_fixed<11, 4> v60 = -bit_shift<-3>(inp[1]) + bit_shift<-3>(inp[7]);
    // ========================== Latency: 2 ==========================
    ap_ufixed<12, 6> v15 = bit_shift<-2>(inp[4]) + bit_shift<1>(v9);
    ap_fixed<12, 5> v6 = bit_shift<-3>(inp[3]) + v0;
    ap_fixed<14, 7> v23 = v18 + v19;
    ap_fixed<15, 8> v22 = v20 + v21;
    ap_fixed<12, 5> v12 = bit_shift<-3>(inp[4]) - v3;
    ap_ufixed<12, 5> v13 = v1 + bit_shift<-2>(inp[5]);
    ap_fixed<14, 7> v28 = v27 + inp[4];
    ap_fixed<13, 6> v29 = v2 + v7;
    ap_ufixed<12, 5> v5 = bit_shift<-3>(inp[5]) + v1;
    ap_fixed<14, 7> v34 = v33 + v2;
    ap_fixed<13, 8> v38 = v36 - bit_shift<2>(v9);
    ap_fixed<13, 6> v37 = -bit_shift<-3>(inp[7]) - v4;
    ap_fixed<14, 7> v43 = v42 - v8;
    ap_fixed<13, 6> v44 = -bit_shift<1>(v3) - v4;
    ap_fixed<14, 7> v48 = v46 + v47;
    ap_fixed<13, 6> v52 = v2 - v10;
    ap_fixed<12, 5> v57 = bit_shift<-3>(inp[4]) + v2;
    ap_fixed<13, 6> v61 = v60 - v7;
    // ========================== Latency: 3 ==========================
    ap_fixed<14, 8> v16 = v14 + v15;
    ap_fixed<14, 7> v11 = v6 - v8;
    ap_fixed<15, 8> v24 = v23 + v22;
    ap_fixed<16, 9> v25 = -v12 + bit_shift<2>(v13);
    ap_fixed<15, 8> v30 = v28 + v0;
    ap_fixed<15, 8> v31 = v29 + bit_shift<2>(v5);
    ap_fixed<14, 7> v35 = v34 + bit_shift<1>(v12);
    ap_fixed<14, 9> v39 = v38 + bit_shift<3>(v10);
    ap_fixed<13, 6> v40 = v37 + v13;
    ap_fixed<15, 8> v45 = v43 + v44;
    ap_fixed<15, 8> v49 = v48 - bit_shift<2>(v0);
    ap_ufixed<14, 9> v53 = v51 + bit_shift<3>(v5);
    ap_fixed<14, 7> v54 = v52 - v5;
    ap_fixed<14, 7> v58 = v57 + v56;
    ap_fixed<13, 6> v69 = v61 + ap_ufixed<1, -2>(0.125);
    // ========================== Latency: 4 ==========================
    ap_fixed<15, 8> v17 = v16 + v11;
    ap_fixed<16, 9> v26 = v24 + v25;
    ap_fixed<16, 9> v32 = v30 + v31;
    ap_fixed<14, 7> v65 = v35 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v41 = v39 + v40;
    ap_fixed<15, 8> v50 = v49 + v6;
    ap_fixed<17, 10> v55 = v53 + v54;
    ap_fixed<15, 8> v59 = v58 + v11;
    // ========================== Latency: 5 ==========================
    ap_fixed<15, 8> v62 = v17 + ap_fixed<1, -2>(-0.125);
    ap_fixed<16, 9> v63 = v26 + ap_ufixed<1, 0>(0.5);
    ap_fixed<16, 9> v64 = v32 + ap_ufixed<1, -1>(0.25);
    ap_fixed<16, 9> v66 = v41 + ap_fixed<1, -2>(-0.125);
    ap_fixed<15, 8> v67 = v50 + ap_ufixed<2, -1>(0.375);
    ap_fixed<17, 10> v68 = v55 + ap_ufixed<2, -1>(0.375);
    out[0] = v62;
    out[1] = v63;
    out[2] = v64;
    out[3] = v65;
    out[4] = v66;
    out[5] = v45;
    out[6] = v67;
    out[7] = v68;
    out[8] = v59;
    out[9] = v69;
}

} // namespace GTADModel_v6

#endif
